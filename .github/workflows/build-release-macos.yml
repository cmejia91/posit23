name: "Positron: Build macOS Release"

# run builds daily at 2am UTC (10p EST) on weekdays for now, or manually
on:
  schedule:
  - cron: "0 2 * * 1-5"
  workflow_dispatch:

jobs:
  revive_agent:
    # The build agent runs on a MacInCloud instance that is frequently (at
    # least once a day) rebooted, which shuts down the build agent. Before we
    # run a build, ensure that the build agent is running; otherwise, the
    # `runs-on: macos` steps will not execute.
    #
    # We run the build agent in a persistent screen session so that it's
    # possible to connect to the live session for debugging purposes with
    # the `screen -r` command.
    name: Revive build agent
    runs-on: [self-hosted, linux]
    steps:
      # Establish an SSH agent into which we can load the key. The build host
      # has the public side of this trusted keypair.
      - name: Setup SSH Keys and known_hosts
        env:
          SSH_AUTH_SOCK: /tmp/ssh_agent.sock
        run: |
          ssh-agent -a $SSH_AUTH_SOCK > /dev/null
          ssh-add - <<< "${{ secrets.MACOS_PRIVATE_SSH_KEY }}"

      - name: Revive Screen session
        id: revive_agent
        env:
          SSH_AUTH_SOCK: /tmp/ssh_agent.sock
        run: |
          # Connect to the host; if there is a screen session running, do
          # nothing, but if there isn't one, start one up now.
          ssh -o "StrictHostKeyChecking no" user229818@NY503.macincloud.com "/bin/zsh -li -c \"if screen -list | grep -q 'No Sockets found'; then screen -dmS agent_session /bin/zsh -li -c 'cd ./actions-runner && ./run.sh'; fi\""

  version_string:
    name: Determine version
    runs-on: self-hosted
    outputs:
      short_version: ${{ steps.short_version.outputs.result }}
      build_number: ${{ steps.build_number.outputs.result }}
    steps:
      # Fetch full history; required so we can determine the build version with rev-list
      - name: Checkout sources
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      # Set up Node 16; needed since the show-version.js script runs under Node
      - uses: actions/setup-node@v3
        with:
          node-version: 16

      # Call version script to determine short version. This is the version
      # string that we will use later to form the file name of the release
      # artifact.
      #
      # Example: 2022.10.0-123
      - name: Determine Version (Short)
        id: short_version
        run: |
          result=`./versions/show-version.js --short`
          echo "result=$result" >> $GITHUB_OUTPUT

      # If we're on main, we will be producing a release later, so make sure
      # that no release is already in place with this tag
      - name: Check for Existing Tag
        id: tag_check
        if: github.ref == 'refs/heads/main'
        run: |
          result=`./versions/show-version.js --short`
          git fetch --tags
          tag_exists=`git tag -l "${result}"`
          if [ -n "${tag_exists}" ]; then exit 78; fi

      # Call again to get just the build number. Example: 123
      - name: Determine Version (Build Number)
        id: build_number
        run: echo "result=$(./versions/show-version.js --build)" >> $GITHUB_OUTPUT

  build-archs:
    name: Build macOS
    runs-on: [self-hosted, macos, arm64]
    needs: [revive_agent, version_string]
    timeout-minutes: 40

    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    strategy:
      max-parallel: 1
      matrix:
        arch: [arm64, x64]
        include:
          - arch: arm64
            arch_terminal: arm64
            homebrew_folder: homebrew
            rust_target_prefix: aarch64
          - arch: x64
            arch_terminal: x86_64
            homebrew_folder: homebrew-x86_64
            rust_target_prefix: x86_64

    steps:
      # Checkout sources
      - name: Checkout sources
        uses: actions/checkout@v3

      # These are already installed for both architectures, but would be required if we switch off
      # a self-hosted runner, so we may as well leave them in
      - name: Install zeromq dependencies
        id: install_zeromq_dependencies
        run: |
          arch -${{matrix.arch_terminal}} /bin/bash -c "~/${{matrix.homebrew_folder}}/bin/brew install pkg-config"
          arch -${{matrix.arch_terminal}} /bin/bash -c "~/${{matrix.homebrew_folder}}/bin/brew install libsodium"

      # Zeromq calls whatever pkg-config version is findable on the PATH to be able to locate
      # libsodium, so we have to ensure the x86_64 version is first on the PATH when compiling for
      # that architecture, so that it finds the x86_64 version of libsodium for zeromq to link against.
      - name: Update PATH to pkg-config for zeromq
        id: update_path_for_zeromq
        if: matrix.arch == 'x64'
        run: |
          echo "~/${{matrix.homebrew_folder}}/bin" >> $GITHUB_PATH

      # Determine R_HOME (for building ark)
      - name: Find Homebrew R installation
        id: r_installation
        run: |
          # Path to the Homebrew build of R, e.g. /Users/user229818/homebrew/Cellar/r
          R_FOLDER=~/${{matrix.homebrew_folder}}/Cellar/r
          # Get the first (and generally) only installed version, e.g. 4.2.2
          R_VERSION=$(ls ${R_FOLDER} | head -1)
          # Form the path to the R binary, e.g. /Users/user229818/homebrew/Cellar/r/4.2.2/bin/R
          R_EXECUTABLE="${R_FOLDER}/${R_VERSION}/bin/R"
          # Invoke the R binary to determine its RHOME directory (usually lib/R)
          R_HOME=$(${R_EXECUTABLE} RHOME)
          # Output the result for consumption in later steps
          echo "Using R at ${R_HOME}"
          echo "r_home=${R_HOME}" >> $GITHUB_OUTPUT

      # Install node_modules binaries and compile the R kernel
      - name: Install dependencies
        env:
          npm_config_arch: ${{ matrix.arch }}
          ARK_BUILD_TYPE: release
          RUST_TARGET: ${{ matrix.rust_target_prefix }}-apple-darwin
          R_HOME: ${{ steps.r_installation.outputs.r_home }}
          POSITRON_GITHUB_PAT: ${{ secrets.POSITRON_GITHUB_PAT }}
        run: yarn --network-timeout 120000

      # Build client
      - name: Build client
        env:
          POSITRON_BUILD_NUMBER: ${{ needs.version_string.outputs.build_number }}
        run: yarn gulp vscode-darwin-${{ matrix.arch }}

      # Compress client to a zip file
      - name: Create client archive
        run: |
          pushd ..
          zip -Xry $GITHUB_WORKSPACE/positron-${{ needs.version_string.outputs.short_version }}-darwin-${{ matrix.arch }}.zip VSCode-darwin-${{ matrix.arch }}
          popd

      # Create build artifact
      - name: Upload client archive
        uses: actions/upload-artifact@v3
        with:
          name: positron-darwin-${{ matrix.arch }}-archive
          path: positron-${{ needs.version_string.outputs.short_version }}-darwin-${{ matrix.arch }}.zip

  macos-universal:
    name: Create macOS universal binary
    needs: [version_string, build-archs]
    runs-on: [self-hosted, macos, arm64]
    timeout-minutes: 40
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    steps:
      # Download arm64 and x64 binaries
      - name: Download arm64 client
        uses: actions/download-artifact@v3
        with:
          name: positron-darwin-arm64-archive

      - name: Download x64 client
        uses: actions/download-artifact@v3
        with:
          name: positron-darwin-x64-archive

      # Expand client archives produced in previous workflow steps
      - name: Expand client archives
        run: |
          unzip positron-${{ needs.version_string.outputs.short_version }}-darwin-arm64.zip
          unzip positron-${{ needs.version_string.outputs.short_version }}-darwin-x64.zip

      # Align architectures. These tasks alter the arm64 and x64 files so that
      # they are suitably symmetric for the electron-universal task that runs
      # below.
      #
      # Specifically:
      #
      # - Remove the ZeroMQ build folders -- they contain build intermediates
      #   that are non-binary but nonetheless differ between arm64 and x64 since
      #   they contain e.g. different compilation flags. electron-universal
      #   chokes if any files (other than binaries) that differ between x64 and
      #   arm64.
      #
      # - Do the same for the `amalthea` build folder
      #
      # - Copy the 'nls.metadata.json' files from x64 to arm64. These files are
      #   semantically identical in both builds, but due to unstable dictionary
      #   key sorting, they don't hash identically.
      - name: Align arm64 and x64 app content
        run: |
          rm -rf VSCode-darwin-arm64/Positron.app/Contents/Resources/app/extensions/jupyter-adapter/node_modules/zeromq/build
          rm -rf VSCode-darwin-x64/Positron.app/Contents/Resources/app/extensions/jupyter-adapter/node_modules/zeromq/build
          rm -rf VSCode-darwin-arm64/Positron.app/Contents/Resources/app/extensions/positron-r/amalthea
          rm -rf VSCode-darwin-x64/Positron.app/Contents/Resources/app/extensions/positron-r/amalthea
          find VSCode-darwin-x64 -name "nls.metadata.json" | sed 's/^[^/]*//' | xargs -I {} cp "VSCode-darwin-x64{}" "VSCode-darwin-arm64{}"

      # Glue together the arm64 and x64 binaries with lipo to create a
      # universal build
      - name: Create universal build
        env:
           VSCODE_ARCH: universal
           DEBUG: "*"
        run: |
          node build/darwin/create-universal-app.js $(pwd)

      # Sign the binaries and set the hardened entitlements
      - name: Sign binaries
        run: |
          security create-keychain -p pwd ${{ runner.temp }}/buildagent.keychain
          security default-keychain -s ${{ runner.temp }}/buildagent.keychain
          security unlock-keychain -p pwd ${{ runner.temp }}/buildagent.keychain
          echo "${{ secrets.MACOS_DEVELOPER_CERTIFICATE }}" | base64 -D > ${{ runner.temp }}/cert.p12
          security import ${{ runner.temp }}/cert.p12 -k ${{ runner.temp }}/buildagent.keychain -P "${{ secrets.MACOS_DEVELOPER_CERTIFICATE_KEY }}" -T /usr/bin/codesign
          export CODESIGN_IDENTITY=$(security find-identity -v -p codesigning ${{ runner.temp }}/buildagent.keychain | grep -oEi "([0-9A-F]{40})" | head -n 1)
          security set-key-partition-list -S apple-tool:,apple:,codesign: -s -k pwd ${{ runner.temp }}/buildagent.keychain
          export AGENT_TEMPDIRECTORY=${{ runner.temp }}
          export VSCODE_ARCH=universal
          DEBUG=electron-osx-sign* node build/darwin/sign.js $(pwd)

      # Compress universal client to a zip file
      - name: Create universal client archive
        run: |
          cd VSCode-darwin-universal
          zip -Xry $GITHUB_WORKSPACE/Positron-${{ needs.version_string.outputs.short_version }}-darwin-universal.zip *

      # Create a GitHub release for the universal binary we just created, if
      # we're running against the main branch
      #
      # TODO: This shouldn't be nested inside the macOS build task, but since
      # macOS is all we're building now, a macOS release and a Positron release
      # are the same thing.
      - name: Create release
        uses: actions/create-release@v1
        id: create_release
        if: github.ref == 'refs/heads/main'
        with:
          draft: false
          prerelease: true
          release_name: ${{ needs.version_string.outputs.short_version }}
          tag_name: ${{ needs.version_string.outputs.short_version }}

      - name: Upload release artifact
        uses: actions/upload-release-asset@v1
        if: github.ref == 'refs/heads/main'
        env:
          GITHUB_TOKEN: ${{ github.token }}
        with:
          upload_url: ${{ steps.create_release.outputs.upload_url }}
          asset_path: Positron-${{ needs.version_string.outputs.short_version }}-darwin-universal.zip
          asset_name: Positron-${{ needs.version_string.outputs.short_version }}-darwin-universal.zip
          asset_content_type: application/zip

      # Create a regular build artifact for the universal archive, to be
      # downloaded from the actions page for testing purposes.
      - name: Upload
        uses: actions/upload-artifact@v3
        with:
          name: positron-darwin-universal-archive
          path: Positron-${{ needs.version_string.outputs.short_version }}-darwin-universal.zip

  status:
    if: ${{ failure() }}
    runs-on: self-hosted
    needs: macos-universal
    steps:
      - name: Notify slack if build fails
        uses: slackapi/slack-github-action@v1.24.0
        id: slack-failure
        with:
          payload: |
            {
              "message": "Positron build ${{ needs.version_string.outputs.build_number }} failed",
              "status": "Failure",
              "run_url": "https://github.com/rstudio/positron/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
